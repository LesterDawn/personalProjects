import math
import random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

random.seed(17)


def load_dataset(filename):
    """
    Load dataset as list and shuffle it
    :param filename: Relative path of Iris
    :return: Shuffled list of dataset
    """
    dataset = pd.read_csv(filename, header=None).values.tolist()
    random.shuffle(dataset)
    return dataset


def select_centroid(dataset, k):
    """
    Randomly select 3 centroids from all of the samples
    :param dataset: Iris dataset
    :param k: Number of centroids
    :return: 3 randomly selected centroids
    """
    return random.sample(dataset, k)


def Euclidean_dist(data1, data2):
    """
    Calculate Euclidean distance between two 4-D samples
    :param data1: Sample being calculated
    :param data2: Centroid
    :return: Euclidean Distance
    """
    result = 0
    for i in range(4):
        result = result + ((data1[i] - data2[i]) ** 2)
    return np.sqrt(result)


def cluster_initialize(dataset):
    """
    Initialize the clusters, i.e. assigning all the samples with a label -1
    E.g. [7.7, 2.8, 6.7, 2.0, 'Iris-virginica'] => [7.7, 2.8, 6.7, 2.0, 'Iris-virginica', -1]
    :param dataset: Iris original dataset
    :return: Dataframe of Iris with an initialized label
    """
    for data in dataset:
        data.append(-1)
    return pd.DataFrame(dataset)


def centroid_cal(cluster):
    """
    Calculate new centroid for the cluster
    :param cluster: A new cluster generated by K-Means
    :return: A new centroid for this cluster
    """
    temp1 = []
    temp2 = []
    for lst in cluster:
        # Only take the first four attributes due to the format of samples
        # Sample point format: [7.7, 2.8, 6.7, 2.0, 'Iris-virginica', 1]
        for i in range(len(lst) - 2):
            temp1.append(lst[i])
        temp2.append(temp1)
        temp1 = []
    return np.mean(temp2, axis=0).tolist()


def k_means(dataset, k):
    """
    K-means procedures:
    Step1: select 3 centroids randomly
    Step2: calculate the Euclidean distance between each sample point and centroid
           and assign each sample to the cluster with the nearest mean point
    Step3: After each sample has assigned, recalculate centroids and return to Step 2
    :param dataset: Dataset with initial labels
    :param k: Number of clusters
    :return: Final centroids and clustering results
    """
    centroids = select_centroid(dataset, k)
    changed_or_not = True  # Flag that indicates the centroid changed or not
    data_cluster = cluster_initialize(dataset)
    try:
        while changed_or_not:
            changed_or_not = False
            # Assign each sample to the cluster with the nearest mean point
            for i in range(len(dataset)):
                minDist = 99999999
                clusterID = -1
                for j in range(k):
                    distance = Euclidean_dist(dataset[i], centroids[j])
                    if distance < minDist:
                        minDist = distance
                        clusterID = j
                if data_cluster.iloc[i, 5] != clusterID:
                    changed_or_not = True
                data_cluster.iloc[i, 5] = clusterID

            # Compute mean points of the clusters
            for i in range(k):
                cluster = data_cluster[data_cluster[5] == i].values.tolist()
                centroids[i] = centroid_cal(cluster)
    except IndexError:
        print("terminated...")
    return centroids, data_cluster


def get_attribute(lst):
    """
    Get the first 2 attributes for plot use
    :param lst: Sample points: [7.7, 2.8, 6.7, 2.0, 'Iris-virginica', 1]...
    :return: The first attribute and the second attribute as 2 arrays
    """
    x = []
    y = []
    for ele in lst:
        x.append(ele[0])
        y.append(ele[1])
    return np.array(x), np.array(y)


def clustering_plot(dataset, centers):
    """
    Predicted cluster plot with the first 2 attributes
    :param dataset: Final clustering result
    :return: A scatter plot of Predicted clusters, in which black triangle centroids are marked
    """
    x0, y0 = get_attribute(dataset[dataset[5] == 0].values.tolist())
    x1, y1 = get_attribute(dataset[dataset[5] == 1].values.tolist())
    x2, y2 = get_attribute(dataset[dataset[5] == 2].values.tolist())
    centroids_x, centroids_y = get_attribute(centers)

    plt.scatter(x0, y0, color='blue')
    plt.scatter(x1, y1, color='green')
    plt.scatter(x2, y2, color='red')
    plt.scatter(centroids_x, centroids_y, color='black', marker='^')
    plt.title('Clustering results')
    plt.xlabel('Sepal length in cm')
    plt.ylabel('Sepal width in cm')
    plt.show()


def actual_plot(dataset):
    """
    Actual classification plot with the first 2 attributes
    :param dataset: Original dataset
    :return: A scatter plot Actual clusters, in which black triangle centroids are marked
    """
    centers = []  # Calculate the centroids of original dataset
    X0, Y0 = get_attribute(dataset[dataset[4] == 'Iris-setosa'].values.tolist())
    centers.append(centroid_cal(dataset[dataset[4] == 'Iris-setosa'].values.tolist()))
    X1, Y1 = get_attribute(dataset[dataset[4] == 'Iris-versicolor'].values.tolist())
    centers.append(centroid_cal(dataset[dataset[4] == 'Iris-versicolor'].values.tolist()))
    X2, Y2 = get_attribute(dataset[dataset[4] == 'Iris-virginica'].values.tolist())
    centers.append(centroid_cal(dataset[dataset[4] == 'Iris-virginica'].values.tolist()))
    centroids_x, centroids_y = get_attribute(centers)

    plt.scatter(X0, Y0, color='red')
    plt.scatter(X1, Y1, color='blue')
    plt.scatter(X2, Y2, color='green')
    plt.scatter(centroids_x, centroids_y, color='black', marker='^')
    plt.title('Actual classification')
    plt.xlabel('Sepal length in cm')
    plt.ylabel('Sepal width in cm')
    plt.show()


def mutual_infor_cal(dataset):
    """
    class0: Iris-versicolor
    class1: Iris-virginica
    class2: Iris-setosa
    :param dataset:
    :return: Mutual Information
    """
    classes = ['Iris-versicolor', 'Iris-virginica', 'Iris-setosa']
    MI = 0
    eps = 1.4e-45
    for i in range(3):
        for cls in classes:
            pw = round(len(dataset[dataset[5] == i]) / len(dataset), 3)
            pc = round(len(dataset[dataset[4] == cls]) / len(dataset), 3)
            pwc = round(len(dataset[(dataset[4] == cls) & (dataset[5] == i)]) / len(dataset), 3)
            MI += pwc * math.log(pwc / (pw * pc) + eps, 2)
    return round(MI, 3)


def normalized_MI_cal(dataset, MI):
    """

    :param dataset: Clustered dataset
    :param MI: Mutual Information
    :return: Normalized MI (NMI)
    """
    classes = ['Iris-versicolor', 'Iris-virginica', 'Iris-setosa']
    Hw = 0
    eps = 1.4e-45
    for i in range(3):
        pw = round(len(dataset[dataset[5] == i]) / len(dataset), 3)
        Hw -= pw * math.log(pw + eps, 2)
    Hc = 0
    for cls in classes:
        pc = round(len(dataset[dataset[4] == cls]) / len(dataset), 3)
        Hc -= pc * math.log(pc + eps, 2)

    NMI = 2.0 * MI / (Hw + Hc)
    return round(NMI, 3)


# Load data
iris = load_dataset('iris.data')

# K-Means clustering
Centroids, clusters = k_means(iris, 3)

# Plot predicted clusters and actual classification
clustering_plot(clusters, Centroids)
actual_plot(clusters)

# Performance Measurement, NMI
Mutual_infor = mutual_infor_cal(clusters)
Normalized_MI = normalized_MI_cal(clusters, Mutual_infor)

print('finished...')
